{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dce4b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 02:43:17.027241: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-29 02:43:17.127438: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:17.127460: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-09-29 02:43:17.150939: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-09-29 02:43:17.692198: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:17.692292: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:17.692302: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3135942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = PIL.Image.open('train_gen/burn through/frame_00031.png')\n",
    "batch_size = 32\n",
    "# img_height = 974\n",
    "# img_width = 800\n",
    "img_height = 100\n",
    "img_width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7e2cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9718 files belonging to 6 classes.\n",
      "Using 7775 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-29 02:43:26.260713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-09-29 02:43:26.260880: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:26.260934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:26.260985: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:26.261034: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:26.261100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:26.261153: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:26.261201: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:26.261249: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-09-29 02:43:26.261260: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-09-29 02:43:26.262217: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  'train_gen',\n",
    "#     rescale=1.0/255.0\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=0,\n",
    "  image_size=(img_height, img_width),\n",
    "#     target_size = (100,100),\n",
    "    shuffle = False,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "776c584b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['burn through', 'contamination', 'good weld', 'lack of fusion', 'lack of penetration', 'misalignment']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c91351f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#       for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(class_names[labels[i]])\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25edba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)\n",
    "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b608e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9fc4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "# image_batch, labels_batch = next(iter(normalized_ds))\n",
    "# first_image = image_batch[0]\n",
    "# # Notice the pixel values are now in `[0,1]`.\n",
    "# print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41547e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd3570c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d4fe174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " rescaling_1 (Rescaling)     (None, 100, 100, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 100, 100, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 50, 50, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 50, 50, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 25, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 25, 25, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 774       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,204,134\n",
      "Trainable params: 1,204,134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f55ea74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "243/243 - 26s - loss: 1.5210 - accuracy: 0.3177 - 26s/epoch - 108ms/step\n",
      "Epoch 2/100\n",
      "243/243 - 16s - loss: 1.5782 - accuracy: 0.3336 - 16s/epoch - 64ms/step\n",
      "Epoch 3/100\n",
      "243/243 - 15s - loss: 1.5669 - accuracy: 0.2675 - 15s/epoch - 63ms/step\n",
      "Epoch 4/100\n",
      "243/243 - 15s - loss: 1.5584 - accuracy: 0.2835 - 15s/epoch - 63ms/step\n",
      "Epoch 5/100\n",
      "243/243 - 15s - loss: 1.5657 - accuracy: 0.2794 - 15s/epoch - 63ms/step\n",
      "Epoch 6/100\n",
      "243/243 - 16s - loss: 1.5574 - accuracy: 0.3164 - 16s/epoch - 64ms/step\n",
      "Epoch 7/100\n",
      "243/243 - 16s - loss: 1.5583 - accuracy: 0.3164 - 16s/epoch - 64ms/step\n",
      "Epoch 8/100\n",
      "243/243 - 16s - loss: 1.5543 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 9/100\n",
      "243/243 - 16s - loss: 1.5540 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 10/100\n",
      "243/243 - 16s - loss: 1.5612 - accuracy: 0.3164 - 16s/epoch - 65ms/step\n",
      "Epoch 11/100\n",
      "243/243 - 16s - loss: 1.5561 - accuracy: 0.3164 - 16s/epoch - 65ms/step\n",
      "Epoch 12/100\n",
      "243/243 - 18s - loss: 1.5635 - accuracy: 0.3164 - 18s/epoch - 72ms/step\n",
      "Epoch 13/100\n",
      "243/243 - 16s - loss: 1.5570 - accuracy: 0.3164 - 16s/epoch - 68ms/step\n",
      "Epoch 14/100\n",
      "243/243 - 16s - loss: 1.5596 - accuracy: 0.3246 - 16s/epoch - 67ms/step\n",
      "Epoch 15/100\n",
      "243/243 - 16s - loss: 1.5440 - accuracy: 0.3082 - 16s/epoch - 67ms/step\n",
      "Epoch 16/100\n",
      "243/243 - 17s - loss: 1.5585 - accuracy: 0.3164 - 17s/epoch - 69ms/step\n",
      "Epoch 17/100\n",
      "243/243 - 16s - loss: 1.5568 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 18/100\n",
      "243/243 - 17s - loss: 1.5514 - accuracy: 0.3164 - 17s/epoch - 69ms/step\n",
      "Epoch 19/100\n",
      "243/243 - 16s - loss: 1.5551 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 20/100\n",
      "243/243 - 17s - loss: 1.5540 - accuracy: 0.3164 - 17s/epoch - 72ms/step\n",
      "Epoch 21/100\n",
      "243/243 - 19s - loss: 1.5578 - accuracy: 0.3164 - 19s/epoch - 77ms/step\n",
      "Epoch 22/100\n",
      "243/243 - 18s - loss: 1.5555 - accuracy: 0.3164 - 18s/epoch - 74ms/step\n",
      "Epoch 23/100\n",
      "243/243 - 21s - loss: 1.5541 - accuracy: 0.3164 - 21s/epoch - 87ms/step\n",
      "Epoch 24/100\n",
      "243/243 - 21s - loss: 1.5536 - accuracy: 0.3164 - 21s/epoch - 86ms/step\n",
      "Epoch 25/100\n",
      "243/243 - 24s - loss: 1.5537 - accuracy: 0.3164 - 24s/epoch - 97ms/step\n",
      "Epoch 26/100\n",
      "243/243 - 18s - loss: 1.5509 - accuracy: 0.3164 - 18s/epoch - 75ms/step\n",
      "Epoch 27/100\n",
      "243/243 - 18s - loss: 1.5494 - accuracy: 0.3164 - 18s/epoch - 74ms/step\n",
      "Epoch 28/100\n",
      "243/243 - 18s - loss: 1.5517 - accuracy: 0.3164 - 18s/epoch - 72ms/step\n",
      "Epoch 29/100\n",
      "243/243 - 17s - loss: 1.5551 - accuracy: 0.3164 - 17s/epoch - 69ms/step\n",
      "Epoch 30/100\n",
      "243/243 - 19s - loss: 1.5528 - accuracy: 0.3164 - 19s/epoch - 77ms/step\n",
      "Epoch 31/100\n",
      "243/243 - 19s - loss: 1.5526 - accuracy: 0.3164 - 19s/epoch - 77ms/step\n",
      "Epoch 32/100\n",
      "243/243 - 18s - loss: 1.5493 - accuracy: 0.3164 - 18s/epoch - 75ms/step\n",
      "Epoch 33/100\n",
      "243/243 - 18s - loss: 1.5501 - accuracy: 0.3164 - 18s/epoch - 72ms/step\n",
      "Epoch 34/100\n",
      "243/243 - 17s - loss: 1.5493 - accuracy: 0.3164 - 17s/epoch - 71ms/step\n",
      "Epoch 35/100\n",
      "243/243 - 18s - loss: 1.5538 - accuracy: 0.3164 - 18s/epoch - 72ms/step\n",
      "Epoch 36/100\n",
      "243/243 - 18s - loss: 1.5479 - accuracy: 0.3164 - 18s/epoch - 72ms/step\n",
      "Epoch 37/100\n",
      "243/243 - 17s - loss: 1.5460 - accuracy: 0.3164 - 17s/epoch - 72ms/step\n",
      "Epoch 38/100\n",
      "243/243 - 17s - loss: 1.5460 - accuracy: 0.3164 - 17s/epoch - 71ms/step\n",
      "Epoch 39/100\n",
      "243/243 - 19s - loss: 1.5475 - accuracy: 0.3164 - 19s/epoch - 79ms/step\n",
      "Epoch 40/100\n",
      "243/243 - 18s - loss: 1.5453 - accuracy: 0.3164 - 18s/epoch - 76ms/step\n",
      "Epoch 41/100\n",
      "243/243 - 18s - loss: 1.5462 - accuracy: 0.3164 - 18s/epoch - 73ms/step\n",
      "Epoch 42/100\n",
      "243/243 - 18s - loss: 1.5464 - accuracy: 0.3164 - 18s/epoch - 74ms/step\n",
      "Epoch 43/100\n",
      "243/243 - 18s - loss: 1.5460 - accuracy: 0.3164 - 18s/epoch - 73ms/step\n",
      "Epoch 44/100\n",
      "243/243 - 18s - loss: 1.5462 - accuracy: 0.3164 - 18s/epoch - 75ms/step\n",
      "Epoch 45/100\n",
      "243/243 - 19s - loss: 1.5461 - accuracy: 0.3164 - 19s/epoch - 76ms/step\n",
      "Epoch 46/100\n",
      "243/243 - 19s - loss: 1.5464 - accuracy: 0.3164 - 19s/epoch - 78ms/step\n",
      "Epoch 47/100\n",
      "243/243 - 20s - loss: 1.5455 - accuracy: 0.3164 - 20s/epoch - 81ms/step\n",
      "Epoch 48/100\n",
      "243/243 - 18s - loss: 1.5461 - accuracy: 0.3164 - 18s/epoch - 75ms/step\n",
      "Epoch 49/100\n",
      "243/243 - 18s - loss: 1.5462 - accuracy: 0.3164 - 18s/epoch - 73ms/step\n",
      "Epoch 50/100\n",
      "243/243 - 17s - loss: 1.5459 - accuracy: 0.3164 - 17s/epoch - 69ms/step\n",
      "Epoch 51/100\n",
      "243/243 - 16s - loss: 1.5466 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 52/100\n",
      "243/243 - 16s - loss: 1.5456 - accuracy: 0.3164 - 16s/epoch - 68ms/step\n",
      "Epoch 53/100\n",
      "243/243 - 16s - loss: 1.5454 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 54/100\n",
      "243/243 - 16s - loss: 1.5454 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 55/100\n",
      "243/243 - 16s - loss: 1.5462 - accuracy: 0.3164 - 16s/epoch - 65ms/step\n",
      "Epoch 56/100\n",
      "243/243 - 16s - loss: 1.5454 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 57/100\n",
      "243/243 - 16s - loss: 1.5461 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 58/100\n",
      "243/243 - 16s - loss: 1.5457 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 59/100\n",
      "243/243 - 16s - loss: 1.5453 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 60/100\n",
      "243/243 - 16s - loss: 1.5454 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 61/100\n",
      "243/243 - 17s - loss: 1.5456 - accuracy: 0.3164 - 17s/epoch - 68ms/step\n",
      "Epoch 62/100\n",
      "243/243 - 16s - loss: 1.5456 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 63/100\n",
      "243/243 - 16s - loss: 1.5460 - accuracy: 0.3164 - 16s/epoch - 65ms/step\n",
      "Epoch 64/100\n",
      "243/243 - 16s - loss: 1.5453 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 65/100\n",
      "243/243 - 16s - loss: 1.5460 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 66/100\n",
      "243/243 - 17s - loss: 1.5466 - accuracy: 0.3164 - 17s/epoch - 68ms/step\n",
      "Epoch 67/100\n",
      "243/243 - 16s - loss: 1.5462 - accuracy: 0.3164 - 16s/epoch - 65ms/step\n",
      "Epoch 68/100\n",
      "243/243 - 16s - loss: 1.5446 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 69/100\n",
      "243/243 - 18s - loss: 1.5452 - accuracy: 0.3164 - 18s/epoch - 73ms/step\n",
      "Epoch 70/100\n",
      "243/243 - 17s - loss: 1.5450 - accuracy: 0.3164 - 17s/epoch - 69ms/step\n",
      "Epoch 71/100\n",
      "243/243 - 19s - loss: 1.5455 - accuracy: 0.3164 - 19s/epoch - 79ms/step\n",
      "Epoch 72/100\n",
      "243/243 - 24s - loss: 1.5451 - accuracy: 0.3164 - 24s/epoch - 99ms/step\n",
      "Epoch 73/100\n",
      "243/243 - 16s - loss: 1.5454 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 74/100\n",
      "243/243 - 16s - loss: 1.5451 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 75/100\n",
      "243/243 - 16s - loss: 1.5452 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 76/100\n",
      "243/243 - 16s - loss: 1.5445 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 77/100\n",
      "243/243 - 16s - loss: 1.5455 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 78/100\n",
      "243/243 - 16s - loss: 1.5452 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 79/100\n",
      "243/243 - 16s - loss: 1.5456 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 80/100\n",
      "243/243 - 16s - loss: 1.5450 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 81/100\n",
      "243/243 - 16s - loss: 1.5452 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 82/100\n",
      "243/243 - 16s - loss: 1.5447 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 83/100\n",
      "243/243 - 16s - loss: 1.5450 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 84/100\n",
      "243/243 - 16s - loss: 1.5451 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 85/100\n",
      "243/243 - 17s - loss: 1.5447 - accuracy: 0.3164 - 17s/epoch - 69ms/step\n",
      "Epoch 86/100\n",
      "243/243 - 16s - loss: 1.5444 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 87/100\n",
      "243/243 - 16s - loss: 1.5448 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 88/100\n",
      "243/243 - 16s - loss: 1.5446 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 89/100\n",
      "243/243 - 16s - loss: 1.5451 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 90/100\n",
      "243/243 - 16s - loss: 1.5449 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 91/100\n",
      "243/243 - 16s - loss: 1.5447 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 92/100\n",
      "243/243 - 16s - loss: 1.5449 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 93/100\n",
      "243/243 - 16s - loss: 1.5449 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 94/100\n",
      "243/243 - 16s - loss: 1.5442 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 95/100\n",
      "243/243 - 16s - loss: 1.5446 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 96/100\n",
      "243/243 - 16s - loss: 1.5451 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 97/100\n",
      "243/243 - 17s - loss: 1.5441 - accuracy: 0.3164 - 17s/epoch - 69ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "243/243 - 16s - loss: 1.5445 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n",
      "Epoch 99/100\n",
      "243/243 - 16s - loss: 1.5440 - accuracy: 0.3164 - 16s/epoch - 66ms/step\n",
      "Epoch 100/100\n",
      "243/243 - 16s - loss: 1.5446 - accuracy: 0.3164 - 16s/epoch - 67ms/step\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "history = model.fit(\n",
    "  normalized_ds,\n",
    "#   validation_data=val_ds,\n",
    "  epochs=epochs,verbose = 2,\n",
    "    shuffle = False,\n",
    "    use_multiprocessing = True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "188d979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Al_defect_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Al_defect_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Al_defect_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a809c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
