{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dce4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3135942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = PIL.Image.open('train_gen/burn through/frame_00031.png')\n",
    "batch_size = 32\n",
    "# img_height = 487\n",
    "# img_width = 400\n",
    "img_height = 100\n",
    "img_width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a7e2cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8268 files belonging to 6 classes.\n",
      "Using 6615 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  'weld_dataset',\n",
    "#     rescale=1.0/255.0\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=0,\n",
    "  image_size=(img_height, img_width),\n",
    "#     target_size = (100,100),\n",
    "    shuffle = False,\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "776c584b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['burn through', 'contamination', 'good weld', 'lack of fusion', 'lack of penetration', 'misalignment']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c91351f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.take(1):\n",
    "#       for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "#         plt.title(class_names[labels[i]])\n",
    "#         plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25edba9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(500).prefetch(buffer_size=AUTOTUNE)\n",
    "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b608e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9fc4c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "# image_batch, labels_batch = next(iter(normalized_ds))\n",
    "# first_image = image_batch[0]\n",
    "# # Notice the pixel values are now in `[0,1]`.\n",
    "# print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2bd4bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception, VGG19, ResNet152, InceptionV3, EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input \n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras import Model \n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41547e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "# model = Sequential([\n",
    "#   layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "#   layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "#   layers.MaxPooling2D(),\n",
    "#   layers.Flatten(),\n",
    "#   layers.Dense(128, activation='relu'),\n",
    "#   layers.Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "\n",
    "headmodel = VGG19(weights = \"imagenet\", include_top = False,\n",
    "             input_tensor = Input(shape = (img_height, img_width, 3)))\n",
    "model = headmodel.output\n",
    "model = AveragePooling2D(pool_size= (3, 3))(model)\n",
    "model = Flatten(name = 'flatten')(model)\n",
    "model = Dense(512, activation = 'relu')(model)\n",
    "model = Dropout(0.2)(model)\n",
    "model = Dense(num_classes, activation = 'softmax')(model)\n",
    "\n",
    "for layer in headmodel.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "final_model = Model(inputs = headmodel.input, outputs = model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd3570c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d4fe174",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 100, 100, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 100, 100, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 50, 50, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 50, 50, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 50, 50, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 25, 25, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 25, 25, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 12, 12, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 12, 12, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 1, 1, 512)        0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,290,118\n",
      "Trainable params: 265,734\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f55ea74c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suman\\Desktop\\venv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207/207 - 12s - loss: 1.2917 - accuracy: 0.4890 - 12s/epoch - 58ms/step\n",
      "Epoch 2/100\n",
      "207/207 - 10s - loss: 0.7095 - accuracy: 0.7327 - 10s/epoch - 47ms/step\n",
      "Epoch 3/100\n",
      "207/207 - 10s - loss: 0.5095 - accuracy: 0.8212 - 10s/epoch - 47ms/step\n",
      "Epoch 4/100\n",
      "207/207 - 10s - loss: 0.4116 - accuracy: 0.8621 - 10s/epoch - 48ms/step\n",
      "Epoch 5/100\n",
      "207/207 - 10s - loss: 0.4207 - accuracy: 0.8366 - 10s/epoch - 49ms/step\n",
      "Epoch 6/100\n",
      "207/207 - 10s - loss: 0.3082 - accuracy: 0.8886 - 10s/epoch - 48ms/step\n",
      "Epoch 7/100\n",
      "207/207 - 10s - loss: 0.2927 - accuracy: 0.9005 - 10s/epoch - 48ms/step\n",
      "Epoch 8/100\n",
      "207/207 - 10s - loss: 0.2253 - accuracy: 0.9075 - 10s/epoch - 48ms/step\n",
      "Epoch 9/100\n",
      "207/207 - 10s - loss: 0.2642 - accuracy: 0.9005 - 10s/epoch - 48ms/step\n",
      "Epoch 10/100\n",
      "207/207 - 10s - loss: 0.2401 - accuracy: 0.8912 - 10s/epoch - 48ms/step\n",
      "Epoch 11/100\n",
      "207/207 - 10s - loss: 0.1963 - accuracy: 0.9231 - 10s/epoch - 48ms/step\n",
      "Epoch 12/100\n",
      "207/207 - 10s - loss: 0.1971 - accuracy: 0.9237 - 10s/epoch - 48ms/step\n",
      "Epoch 13/100\n",
      "207/207 - 10s - loss: 0.2049 - accuracy: 0.9102 - 10s/epoch - 49ms/step\n",
      "Epoch 14/100\n",
      "207/207 - 10s - loss: 0.1806 - accuracy: 0.9274 - 10s/epoch - 49ms/step\n",
      "Epoch 15/100\n",
      "207/207 - 10s - loss: 0.1645 - accuracy: 0.9430 - 10s/epoch - 48ms/step\n",
      "Epoch 16/100\n",
      "207/207 - 10s - loss: 0.1622 - accuracy: 0.9435 - 10s/epoch - 48ms/step\n",
      "Epoch 17/100\n",
      "207/207 - 10s - loss: 0.2025 - accuracy: 0.9203 - 10s/epoch - 48ms/step\n",
      "Epoch 18/100\n",
      "207/207 - 10s - loss: 0.1621 - accuracy: 0.9400 - 10s/epoch - 48ms/step\n",
      "Epoch 19/100\n",
      "207/207 - 10s - loss: 0.1281 - accuracy: 0.9568 - 10s/epoch - 49ms/step\n",
      "Epoch 20/100\n",
      "207/207 - 10s - loss: 0.1282 - accuracy: 0.9513 - 10s/epoch - 48ms/step\n",
      "Epoch 21/100\n",
      "207/207 - 10s - loss: 0.1368 - accuracy: 0.9513 - 10s/epoch - 48ms/step\n",
      "Epoch 22/100\n",
      "207/207 - 10s - loss: 0.1255 - accuracy: 0.9528 - 10s/epoch - 48ms/step\n",
      "Epoch 23/100\n",
      "207/207 - 10s - loss: 0.1126 - accuracy: 0.9560 - 10s/epoch - 48ms/step\n",
      "Epoch 24/100\n",
      "207/207 - 10s - loss: 0.1003 - accuracy: 0.9637 - 10s/epoch - 48ms/step\n",
      "Epoch 25/100\n",
      "207/207 - 10s - loss: 0.0984 - accuracy: 0.9640 - 10s/epoch - 48ms/step\n",
      "Epoch 26/100\n",
      "207/207 - 10s - loss: 0.0981 - accuracy: 0.9692 - 10s/epoch - 48ms/step\n",
      "Epoch 27/100\n",
      "207/207 - 10s - loss: 0.1792 - accuracy: 0.9444 - 10s/epoch - 48ms/step\n",
      "Epoch 28/100\n",
      "207/207 - 10s - loss: 0.1018 - accuracy: 0.9657 - 10s/epoch - 49ms/step\n",
      "Epoch 29/100\n",
      "207/207 - 10s - loss: 0.1000 - accuracy: 0.9595 - 10s/epoch - 48ms/step\n",
      "Epoch 30/100\n",
      "207/207 - 10s - loss: 0.1314 - accuracy: 0.9518 - 10s/epoch - 48ms/step\n",
      "Epoch 31/100\n",
      "207/207 - 10s - loss: 0.1039 - accuracy: 0.9605 - 10s/epoch - 48ms/step\n",
      "Epoch 32/100\n",
      "207/207 - 10s - loss: 0.1226 - accuracy: 0.9542 - 10s/epoch - 48ms/step\n",
      "Epoch 33/100\n",
      "207/207 - 10s - loss: 0.0869 - accuracy: 0.9676 - 10s/epoch - 48ms/step\n",
      "Epoch 34/100\n",
      "207/207 - 10s - loss: 0.0985 - accuracy: 0.9689 - 10s/epoch - 48ms/step\n",
      "Epoch 35/100\n",
      "207/207 - 10s - loss: 0.0692 - accuracy: 0.9748 - 10s/epoch - 48ms/step\n",
      "Epoch 36/100\n",
      "207/207 - 10s - loss: 0.0903 - accuracy: 0.9710 - 10s/epoch - 48ms/step\n",
      "Epoch 37/100\n",
      "207/207 - 10s - loss: 0.0879 - accuracy: 0.9645 - 10s/epoch - 48ms/step\n",
      "Epoch 38/100\n",
      "207/207 - 10s - loss: 0.1028 - accuracy: 0.9645 - 10s/epoch - 48ms/step\n",
      "Epoch 39/100\n",
      "207/207 - 10s - loss: 0.0719 - accuracy: 0.9743 - 10s/epoch - 48ms/step\n",
      "Epoch 40/100\n",
      "207/207 - 10s - loss: 0.0731 - accuracy: 0.9704 - 10s/epoch - 48ms/step\n",
      "Epoch 41/100\n",
      "207/207 - 10s - loss: 0.0930 - accuracy: 0.9757 - 10s/epoch - 49ms/step\n",
      "Epoch 42/100\n",
      "207/207 - 10s - loss: 0.0884 - accuracy: 0.9690 - 10s/epoch - 48ms/step\n",
      "Epoch 43/100\n",
      "207/207 - 10s - loss: 0.0560 - accuracy: 0.9835 - 10s/epoch - 48ms/step\n",
      "Epoch 44/100\n",
      "207/207 - 10s - loss: 0.0674 - accuracy: 0.9760 - 10s/epoch - 48ms/step\n",
      "Epoch 45/100\n",
      "207/207 - 10s - loss: 0.0727 - accuracy: 0.9773 - 10s/epoch - 48ms/step\n",
      "Epoch 46/100\n",
      "207/207 - 10s - loss: 0.1032 - accuracy: 0.9628 - 10s/epoch - 48ms/step\n",
      "Epoch 47/100\n",
      "207/207 - 10s - loss: 0.1782 - accuracy: 0.9379 - 10s/epoch - 48ms/step\n",
      "Epoch 48/100\n",
      "207/207 - 10s - loss: 0.0794 - accuracy: 0.9651 - 10s/epoch - 48ms/step\n",
      "Epoch 49/100\n",
      "207/207 - 10s - loss: 0.0525 - accuracy: 0.9829 - 10s/epoch - 48ms/step\n",
      "Epoch 50/100\n",
      "207/207 - 10s - loss: 0.0592 - accuracy: 0.9803 - 10s/epoch - 48ms/step\n",
      "Epoch 51/100\n",
      "207/207 - 10s - loss: 0.0470 - accuracy: 0.9853 - 10s/epoch - 48ms/step\n",
      "Epoch 52/100\n",
      "207/207 - 10s - loss: 0.0831 - accuracy: 0.9658 - 10s/epoch - 48ms/step\n",
      "Epoch 53/100\n",
      "207/207 - 10s - loss: 0.1147 - accuracy: 0.9646 - 10s/epoch - 48ms/step\n",
      "Epoch 54/100\n",
      "207/207 - 10s - loss: 0.0758 - accuracy: 0.9746 - 10s/epoch - 48ms/step\n",
      "Epoch 55/100\n",
      "207/207 - 10s - loss: 0.0582 - accuracy: 0.9779 - 10s/epoch - 48ms/step\n",
      "Epoch 56/100\n",
      "207/207 - 10s - loss: 0.0731 - accuracy: 0.9728 - 10s/epoch - 48ms/step\n",
      "Epoch 57/100\n",
      "207/207 - 10s - loss: 0.0766 - accuracy: 0.9670 - 10s/epoch - 50ms/step\n",
      "Epoch 58/100\n",
      "207/207 - 10s - loss: 0.1166 - accuracy: 0.9580 - 10s/epoch - 49ms/step\n",
      "Epoch 59/100\n",
      "207/207 - 10s - loss: 0.0571 - accuracy: 0.9810 - 10s/epoch - 48ms/step\n",
      "Epoch 60/100\n",
      "207/207 - 10s - loss: 0.0397 - accuracy: 0.9884 - 10s/epoch - 48ms/step\n",
      "Epoch 61/100\n",
      "207/207 - 10s - loss: 0.0603 - accuracy: 0.9763 - 10s/epoch - 48ms/step\n",
      "Epoch 62/100\n",
      "207/207 - 10s - loss: 0.0503 - accuracy: 0.9832 - 10s/epoch - 48ms/step\n",
      "Epoch 63/100\n",
      "207/207 - 10s - loss: 0.0503 - accuracy: 0.9816 - 10s/epoch - 48ms/step\n",
      "Epoch 64/100\n",
      "207/207 - 10s - loss: 0.0591 - accuracy: 0.9794 - 10s/epoch - 49ms/step\n",
      "Epoch 65/100\n",
      "207/207 - 10s - loss: 0.0852 - accuracy: 0.9696 - 10s/epoch - 49ms/step\n",
      "Epoch 66/100\n",
      "207/207 - 10s - loss: 0.0421 - accuracy: 0.9832 - 10s/epoch - 48ms/step\n",
      "Epoch 67/100\n",
      "207/207 - 10s - loss: 0.0726 - accuracy: 0.9776 - 10s/epoch - 48ms/step\n",
      "Epoch 68/100\n",
      "207/207 - 10s - loss: 0.0944 - accuracy: 0.9627 - 10s/epoch - 48ms/step\n",
      "Epoch 69/100\n",
      "207/207 - 10s - loss: 0.0681 - accuracy: 0.9775 - 10s/epoch - 48ms/step\n",
      "Epoch 70/100\n",
      "207/207 - 10s - loss: 0.0401 - accuracy: 0.9867 - 10s/epoch - 48ms/step\n",
      "Epoch 71/100\n",
      "207/207 - 10s - loss: 0.0684 - accuracy: 0.9785 - 10s/epoch - 48ms/step\n",
      "Epoch 72/100\n",
      "207/207 - 10s - loss: 0.0692 - accuracy: 0.9751 - 10s/epoch - 49ms/step\n",
      "Epoch 73/100\n",
      "207/207 - 10s - loss: 0.0408 - accuracy: 0.9875 - 10s/epoch - 49ms/step\n",
      "Epoch 74/100\n",
      "207/207 - 10s - loss: 0.0646 - accuracy: 0.9761 - 10s/epoch - 49ms/step\n",
      "Epoch 75/100\n",
      "207/207 - 10s - loss: 0.0690 - accuracy: 0.9754 - 10s/epoch - 49ms/step\n",
      "Epoch 76/100\n",
      "207/207 - 10s - loss: 0.0321 - accuracy: 0.9890 - 10s/epoch - 50ms/step\n",
      "Epoch 77/100\n",
      "207/207 - 10s - loss: 0.0454 - accuracy: 0.9861 - 10s/epoch - 49ms/step\n",
      "Epoch 78/100\n",
      "207/207 - 10s - loss: 0.0372 - accuracy: 0.9867 - 10s/epoch - 49ms/step\n",
      "Epoch 79/100\n",
      "207/207 - 10s - loss: 0.0476 - accuracy: 0.9855 - 10s/epoch - 49ms/step\n",
      "Epoch 80/100\n",
      "207/207 - 10s - loss: 0.0654 - accuracy: 0.9723 - 10s/epoch - 49ms/step\n",
      "Epoch 81/100\n",
      "207/207 - 10s - loss: 0.0412 - accuracy: 0.9853 - 10s/epoch - 49ms/step\n",
      "Epoch 82/100\n",
      "207/207 - 10s - loss: 0.0297 - accuracy: 0.9902 - 10s/epoch - 49ms/step\n",
      "Epoch 83/100\n",
      "207/207 - 10s - loss: 0.0449 - accuracy: 0.9819 - 10s/epoch - 49ms/step\n",
      "Epoch 84/100\n",
      "207/207 - 10s - loss: 0.1192 - accuracy: 0.9661 - 10s/epoch - 49ms/step\n",
      "Epoch 85/100\n",
      "207/207 - 10s - loss: 0.0687 - accuracy: 0.9787 - 10s/epoch - 49ms/step\n",
      "Epoch 86/100\n",
      "207/207 - 10s - loss: 0.0450 - accuracy: 0.9835 - 10s/epoch - 49ms/step\n",
      "Epoch 87/100\n",
      "207/207 - 10s - loss: 0.0317 - accuracy: 0.9888 - 10s/epoch - 49ms/step\n",
      "Epoch 88/100\n",
      "207/207 - 10s - loss: 0.0693 - accuracy: 0.9791 - 10s/epoch - 49ms/step\n",
      "Epoch 89/100\n",
      "207/207 - 10s - loss: 0.0470 - accuracy: 0.9846 - 10s/epoch - 49ms/step\n",
      "Epoch 90/100\n",
      "207/207 - 10s - loss: 0.0398 - accuracy: 0.9875 - 10s/epoch - 49ms/step\n",
      "Epoch 91/100\n",
      "207/207 - 10s - loss: 0.0429 - accuracy: 0.9853 - 10s/epoch - 49ms/step\n",
      "Epoch 92/100\n",
      "207/207 - 10s - loss: 0.0304 - accuracy: 0.9878 - 10s/epoch - 49ms/step\n",
      "Epoch 93/100\n",
      "207/207 - 10s - loss: 0.0679 - accuracy: 0.9748 - 10s/epoch - 49ms/step\n",
      "Epoch 94/100\n",
      "207/207 - 10s - loss: 0.0762 - accuracy: 0.9740 - 10s/epoch - 49ms/step\n",
      "Epoch 95/100\n",
      "207/207 - 10s - loss: 0.0443 - accuracy: 0.9878 - 10s/epoch - 49ms/step\n",
      "Epoch 96/100\n",
      "207/207 - 10s - loss: 0.0308 - accuracy: 0.9872 - 10s/epoch - 49ms/step\n",
      "Epoch 97/100\n",
      "207/207 - 10s - loss: 0.0345 - accuracy: 0.9878 - 10s/epoch - 49ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100\n",
      "207/207 - 10s - loss: 0.0317 - accuracy: 0.9878 - 10s/epoch - 49ms/step\n",
      "Epoch 99/100\n",
      "207/207 - 10s - loss: 0.0344 - accuracy: 0.9890 - 10s/epoch - 49ms/step\n",
      "Epoch 100/100\n",
      "207/207 - 10s - loss: 0.0808 - accuracy: 0.9714 - 10s/epoch - 49ms/step\n"
     ]
    }
   ],
   "source": [
    "epochs=100\n",
    "history = final_model.fit(\n",
    "  normalized_ds,\n",
    "#   validation_data=val_ds,\n",
    "  epochs=epochs,verbose = 2,\n",
    "    shuffle = False,\n",
    "    use_multiprocessing = True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a809c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: weldModel\\assets\n"
     ]
    }
   ],
   "source": [
    "final_model.save('weldModel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
